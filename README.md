# ğŸ¤– Chatbot using Groq LLM + LangChain

This project is a **chatbot prototype** built using **LangChain** and powered by the **Groq LLM**. It runs entirely inside a **Google Colab notebook**, making it easy to test and iterate quickly without setting up a separate app or frontend.
This is NOT a conversational chatbot (no memory used).
For a full conversational bot, memory and higher-level chains like ConversationalRetrievalChain can be added later.
---

## ğŸ“’ Project Overview

The chatbot accepts user input and returns intelligent responses using Groqâ€™s fast LLM. It demonstrates working with LangChain's chaining mechanisms and LangChain Expression Language (LCEL) to streamline prompt handling and response generation.

---

## ğŸ“ Project Structure


---

## ğŸ§ª Tech Stack

- ğŸ§  **LangChain**
- âš¡ **Groq LLM**
- ğŸ” **Python-dotenv** (for API key handling)
- ğŸ§ª **Google Colab** (for development and testing)

---

## ğŸ“Œ Setup Instructions

1. Open the notebook in Google Colab.
2. Upload a `.env` file with your Groq API key:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
Run the cells and start chatting!
